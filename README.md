# 무한리필 가게 크롤링 프로젝트 🍽️

**4단계: 서울 완전 커버리지 및 자동화 시스템**

서울 25개 구 무한리필 맛집 완전 데이터베이스 구축을 위한 고도화된 크롤링 시스템입니다.

## 🎯 4단계 주요 목표

### 📍 서울 완전 커버리지

- **현재**: 8개 주요 지역 (200-400개 가게)
- **목표**: 서울 25개 구 완전 커버 (1,000-2,000개 가게)
- **정밀도**: 동별/역세권별 세분화 크롤링

### 🤖 완전 자동화 시스템

- **주간 순환 스케줄**: 구별 우선순위 기반 자동 크롤링
- **실시간 모니터링**: 대시보드 및 진행상황 추적
- **장애 대응**: 자동 오류 감지 및 복구

### 🗺️ 지능형 격자 시스템

- **역세권 기반**: 지하철역 중심 상권 분석
- **동적 최적화**: 실시간 결과 기반 격자 조정
- **밀도 적응**: 상권 규모별 맞춤 검색 전략

## 🏗️ 시스템 아키텍처

### 4단계 핵심 모듈

```
📁 4단계 서울 완전 커버리지
├── 🗺️ seoul_districts.py      # 서울 25개 구 데이터베이스
├── ⏰ seoul_scheduler.py       # 자동 스케줄링 시스템
├── 📊 seoul_dashboard.py       # 실시간 모니터링 대시보드
└── 🔧 seoul_error_handler.py   # 장애 대응 시스템
```

### 서울 25개 구 분류 체계

#### 🏆 Tier 1: 초고밀도 상권 (3개 구)

- **강남구**: 80개 예상 가게 (강남역, 선릉역, 압구정로데오)
- **마포구**: 75개 예상 가게 (홍대입구, 합정, 상암)
- **서초구**: 70개 예상 가게 (교대, 사당, 방배)

#### 🥈 Tier 2: 고밀도 상권 (5개 구)

- **송파구**: 65개 예상 가게 (잠실, 석촌호수, 가락시장)
- **영등포구**: 60개 예상 가게 (여의도, 영등포역, 당산)
- **용산구**: 55개 예상 가게 (이태원, 용산역, 한강진)
- **성동구**: 55개 예상 가게 (건대입구, 성수동, 왕십리)
- **광진구**: 50개 예상 가게 (건대, 구의역, 자양동)

#### 🥉 Tier 3: 중밀도 상권 (6개 구)

- **관악구**: 45개 예상 가게 (신림, 서울대입구, 봉천)
- **서대문구**: 40개 예상 가게 (신촌, 이대, 홍제)
- **종로구**: 40개 예상 가게 (종각, 인사동, 대학로)
- **중구**: 35개 예상 가게 (명동, 동대문, 을지로)
- **성북구**: 35개 예상 가게 (성신여대입구, 한성대입구)
- **동대문구**: 35개 예상 가게 (회기, 외대앞, 청량리)

#### 🏠 Tier 4: 주거 중심 (8개 구)

- **노원구, 강북구, 은평구, 강서구**: 각 30개 예상 가게
- **양천구, 구로구, 금천구, 동작구**: 각 25개 예상 가게

#### 🌱 Tier 5: 저밀도 (3개 구)

- **강동구, 중랑구, 도봉구**: 각 20개 예상 가게

## 🚀 사용법

### 4단계 명령어

```bash
# 서울 25개 구 완전 커버리지 크롤링
python main.py stage4

# 서울 자동 스케줄러 시작 (24/7 무인 운영)
python main.py seoul-scheduler

# 서울 커버리지 대시보드 확인
python main.py seoul-dashboard

# 4단계 시스템 테스트
python main.py test-stage4
```

### 기존 명령어

```bash
# 3단계 고도화 크롤링
python main.py stage3

# 강화된 크롤링 (단일 실행)
python main.py enhanced

# 지역 확장 크롤링
python main.py expansion

# 데이터베이스 통계 확인
python main.py stats

# 3단계 기능 테스트
python main.py test-stage3
```

## 📅 주간 자동 스케줄

### 월요일: Tier 1 (초고밀도)

- 02:00 강남구
- 04:00 마포구
- 06:00 서초구

### 화요일: Tier 2-1 (고밀도)

- 02:00 송파구
- 04:00 영등포구
- 06:00 용산구

### 수요일: Tier 2-2 (고밀도)

- 02:00 성동구
- 04:00 광진구

### 목요일: Tier 3-1 (중밀도)

- 01:00 관악구
- 03:00 서대문구
- 05:00 종로구
- 07:00 중구

### 금요일: Tier 3-2 (중밀도)

- 02:00 성북구
- 04:00 동대문구

### 토요일: Tier 4 (주거 중심)

- 01:00 노원구
- 02:30 강북구
- 04:00 은평구
- 05:30 강서구
- 07:00 양천구

### 일요일: Tier 4&5 (나머지)

- 01:00 구로구
- 02:00 금천구
- 03:00 동작구
- 04:00 강동구
- 05:00 중랑구
- 06:00 도봉구

## 📊 실시간 모니터링

### 대시보드 기능

- **커버리지 현황**: 25개 구별 완료율 실시간 추적
- **성능 지표**: 처리 속도, 성공률, 가게 수 통계
- **스케줄 관리**: 다음 예정 작업 및 진행상황
- **오류 추적**: 실시간 장애 감지 및 대응

### 주간 리포트 자동 생성

- **완료율 분석**: 구별/티어별 성과 측정
- **품질 지표**: 데이터 정확도 및 완성도
- **트렌드 분석**: 시간대별/지역별 패턴 분석

## 🛠️ 설치 및 설정

### 1. 의존성 설치

```bash
pip install -r requirements.txt
```

### 2. 데이터베이스 설정

```bash
# PostgreSQL + PostGIS 설정
sudo apt-get install postgresql postgis

# 데이터베이스 생성
createdb refill_spots
psql refill_spots -c "CREATE EXTENSION postgis;"
```

### 3. API 키 설정 (선택사항)

```python
# config.py
KAKAO_API_KEY = "your_kakao_api_key"      # 지오코딩용 (일일 300,000회)
NAVER_CLIENT_ID = "your_naver_client_id"   # 백업 지오코딩 (일일 100,000회)
NAVER_CLIENT_SECRET = "your_naver_secret"
```

## 📈 예상 성과

### 데이터 규모

- **총 가게 수**: 1,000-2,000개 (서울 무한리필 완전 DB)
- **커버리지**: 서울 25개 구 100% 커버
- **정확도**: 좌표 98%+, 가격 정규화 95%+

### 자동화 효과

- **무인 운영**: 주 7일 24시간 자동 크롤링
- **유지보수**: 수동 작업 95% 감소
- **실시간 대응**: 장애 감지 및 자동 복구

### 데이터 품질

- **좌표 완성도**: 90% → 98%+ (지오코딩 API)
- **가격 정규화**: 텍스트 → 구조화된 JSON
- **카테고리 표준화**: 원본 태그 → 계층적 분류
- **중복 제거**: 자동 감지 및 통합

## 🔧 기술 스택

### 4단계 추가 기술

- **스케줄링**: `schedule` 라이브러리
- **멀티스레딩**: 비동기 작업 처리
- **실시간 모니터링**: JSON 기반 대시보드
- **장애 대응**: 패턴 기반 자동 복구

### 기존 기술 스택

- **크롤링**: Selenium, BeautifulSoup
- **데이터베이스**: PostgreSQL + PostGIS
- **지오코딩**: Kakao/Naver API
- **데이터 처리**: Pandas, NumPy

## 📝 변경 이력

### 4단계 (2024.12) - 서울 완전 커버리지

- ✅ 서울 25개 구 완전 데이터베이스 구축
- ✅ 주간 순환 자동 스케줄링 시스템
- ✅ 실시간 모니터링 대시보드
- ✅ 지능형 격자 시스템 (역세권 기반)
- ✅ 장애 대응 자동화

### 3단계 (2024.11) - 데이터 품질 고도화

- ✅ 지오코딩 API 연동 (좌표 완성도 98%+)
- ✅ 한국어 가격 정규화 시스템
- ✅ 계층적 카테고리 매핑
- ✅ 중복 제거 알고리즘

### 2단계 (2024.10) - 성능 최적화

- ✅ 강화된 파싱 로직
- ✅ 배치 처리 시스템
- ✅ 오류 처리 개선

### 1단계 (2024.09) - MVP

- ✅ 기본 크롤링 시스템
- ✅ PostgreSQL 연동
- ✅ 12개 주요 지역 커버

## 🤝 기여하기

1. Fork the Project
2. Create your Feature Branch (`git checkout -b feature/AmazingFeature`)
3. Commit your Changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the Branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## 📄 라이선스

이 프로젝트는 MIT 라이선스 하에 배포됩니다. 자세한 내용은 `LICENSE` 파일을 참조하세요.

## 📞 연락처

프로젝트 관련 문의: [GitHub Issues](https://github.com/yourusername/refill-spot-crawler/issues)

---

**🎯 4단계 목표: 서울 무한리필 맛집 완전 정복! 🗺️**
