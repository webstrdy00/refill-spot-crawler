"""
Supabase MCPë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ê¸°
"""
import asyncio
import logging
from typing import List, Dict, Optional
from .supabase_migration import SupabaseMigration

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('supabase_mcp_migration.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class SupabaseMCPMigration:
    """Supabase MCPë¥¼ í™œìš©í•œ ì‹¤ì‹œê°„ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    
    def __init__(self, supabase_project_id: str = "ykztepbfcocxmtotrdbk"):
        self.supabase_project_id = supabase_project_id
        self.migration = SupabaseMigration(supabase_project_id)
        
    async def execute_migration(self, limit: Optional[int] = None, batch_size: int = 5):
        """Supabase MCPë¥¼ í†µí•œ ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰"""
        try:
            # 1. í¬ë¡¤ëŸ¬ ë°ì´í„° ì¡°íšŒ
            logger.info("ğŸ” í¬ë¡¤ëŸ¬ ë°ì´í„° ì¡°íšŒ ì¤‘...")
            stores = self.migration.get_crawler_stores(limit)
            
            if not stores:
                logger.warning("ë§ˆì´ê·¸ë ˆì´ì…˜í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
                return {'total': 0, 'success': 0, 'failed': 0}
            
            logger.info(f"ğŸ“Š ì´ {len(stores)}ê°œ ê°€ê²Œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œì‘")
            
            # 2. ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            stats = {'total': len(stores), 'success': 0, 'failed': 0}
            
            for i in range(0, len(stores), batch_size):
                batch = stores[i:i + batch_size]
                logger.info(f"ğŸ“¦ ë°°ì¹˜ {i//batch_size + 1} ì²˜ë¦¬ ì¤‘ ({len(batch)}ê°œ)")
                
                batch_stats = await self._process_batch(batch)
                stats['success'] += batch_stats['success']
                stats['failed'] += batch_stats['failed']
                
                # ë°°ì¹˜ ê°„ ì§€ì—°
                if i + batch_size < len(stores):
                    await asyncio.sleep(1)
            
            # ê²°ê³¼ ë¦¬í¬íŠ¸
            logger.info("ğŸ‰ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
            logger.info(f"ğŸ“ˆ ê²°ê³¼: ì´ {stats['total']}ê°œ ì¤‘ ì„±ê³µ {stats['success']}ê°œ, ì‹¤íŒ¨ {stats['failed']}ê°œ")
            
            return stats
            
        except Exception as e:
            logger.error(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            raise
        finally:
            self.migration.close()
    
    async def _process_batch(self, stores: List[Dict]) -> Dict[str, int]:
        """ë°°ì¹˜ ë‹¨ìœ„ ê°€ê²Œ ì²˜ë¦¬"""
        stats = {'success': 0, 'failed': 0}
        
        for store in stores:
            try:
                # ë°ì´í„° ê°€ê³µ
                processed_data = self.migration.process_store_data(store)
                
                # Supabaseì— ì‚½ì…
                success = await self._insert_store_to_supabase(processed_data)
                
                if success:
                    stats['success'] += 1
                    logger.info(f"âœ… ì‚½ì… ì„±ê³µ: {processed_data['name']}")
                else:
                    stats['failed'] += 1
                    logger.error(f"âŒ ì‚½ì… ì‹¤íŒ¨: {processed_data['name']}")
                
            except Exception as e:
                stats['failed'] += 1
                logger.error(f"âŒ ì²˜ë¦¬ ì‹¤íŒ¨ ({store.get('name', 'Unknown')}): {e}")
                continue
        
        return stats
    
    async def _insert_store_to_supabase(self, data: Dict) -> bool:
        """Supabase MCPë¥¼ í†µí•œ ê°€ê²Œ ë°ì´í„° ì‚½ì…"""
        try:
            # 1. ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬
            await self._ensure_categories(data['categories'])
            
            # 2. ê°€ê²Œ ë°ì´í„° ì‚½ì…
            store_sql = self._build_store_insert_sql(data)
            
            # Supabase MCP ì‹¤í–‰ (ì‹¤ì œë¡œëŠ” mcp_supabase-mcp_execute_sql í˜¸ì¶œ)
            logger.debug(f"SQL ì‹¤í–‰ ì¤€ë¹„: {data['name']}")
            
            # ì—¬ê¸°ì„œ ì‹¤ì œ MCP í˜¸ì¶œì„ ì‹œë®¬ë ˆì´ì…˜
            # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” MCP í•¨ìˆ˜ë¥¼ ì§ì ‘ í˜¸ì¶œ
            result = await self._execute_sql_via_mcp(store_sql)
            
            if result:
                # 3. ì¹´í…Œê³ ë¦¬ ì—°ê²° ì²˜ë¦¬
                await self._link_store_categories(data['name'], data['categories'])
                return True
            
            return False
            
        except Exception as e:
            logger.error(f"Supabase ì‚½ì… ì˜¤ë¥˜: {e}")
            return False
    
    async def _ensure_categories(self, categories: List[str]):
        """ì¹´í…Œê³ ë¦¬ ì¡´ì¬ í™•ì¸ ë° ìƒì„±"""
        for category in categories:
            category_sql = f"""
                INSERT INTO categories (name) 
                VALUES ('{category.replace("'", "''")}') 
                ON CONFLICT (name) DO NOTHING;
            """
            
            await self._execute_sql_via_mcp(category_sql)
    
    async def _execute_sql_via_mcp(self, sql: str) -> bool:
        """Supabase MCPë¥¼ í†µí•œ SQL ì‹¤í–‰"""
        try:
            # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” ì—¬ê¸°ì„œ MCP í•¨ìˆ˜ë¥¼ í˜¸ì¶œ
            # await mcp_supabase_execute_sql(project_id=self.supabase_project_id, query=sql)
            
            # í˜„ì¬ëŠ” ì‹œë®¬ë ˆì´ì…˜
            logger.debug(f"SQL ì‹¤í–‰: {sql[:100]}...")
            await asyncio.sleep(0.1)  # ë„¤íŠ¸ì›Œí¬ ì§€ì—° ì‹œë®¬ë ˆì´ì…˜
            return True
            
        except Exception as e:
            logger.error(f"SQL ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return False
    
    def _build_store_insert_sql(self, data: Dict) -> str:
        """ê°€ê²Œ ì‚½ì… SQL ë¬¸ ìƒì„±"""
        # ë°°ì—´ ë°ì´í„° ì²˜ë¦¬
        refill_items_array = "ARRAY[" + ",".join([f"'{item.replace("'", "''")}'" for item in data['refill_items']]) + "]"
        image_urls_array = "ARRAY[" + ",".join([f"'{url.replace("'", "''")}'" for url in data['image_urls']]) + "]"
        
        sql = f"""
            INSERT INTO stores (
                name, address, description, 
                position_lat, position_lng, position_x, position_y,
                naver_rating, kakao_rating, open_hours, 
                price, refill_items, image_urls
            ) VALUES (
                '{data['name'].replace("'", "''")}',
                '{data['address'].replace("'", "''")}',
                '{data['description'].replace("'", "''")}',
                {data['position_lat']},
                {data['position_lng']},
                {data['position_x']},
                {data['position_y']},
                {data['naver_rating'] if data['naver_rating'] else 'NULL'},
                {data['kakao_rating'] if data['kakao_rating'] else 'NULL'},
                {f"'{data['open_hours'].replace("'", "''")}'" if data['open_hours'] else 'NULL'},
                {f"'{data['price'].replace("'", "''")}'" if data['price'] else 'NULL'},
                {refill_items_array},
                {image_urls_array}
            ) RETURNING id;
        """
        
        return sql
    
    async def _link_store_categories(self, store_name: str, categories: List[str]):
        """ê°€ê²Œ-ì¹´í…Œê³ ë¦¬ ì—°ê²°"""
        for category in categories:
            link_sql = f"""
                INSERT INTO store_categories (store_id, category_id)
                SELECT s.id, c.id 
                FROM stores s, categories c 
                WHERE s.name = '{store_name.replace("'", "''")}' 
                AND c.name = '{category.replace("'", "''")}';
            """
            
            await self._execute_sql_via_mcp(link_sql)
    
    async def test_connection(self) -> bool:
        """Supabase ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
            test_sql = "SELECT COUNT(*) FROM stores;"
            result = await self._execute_sql_via_mcp(test_sql)
            
            if result:
                logger.info("âœ… Supabase ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                logger.error("âŒ Supabase ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
                return False
                
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
            return False
    
    async def get_migration_preview(self, limit: int = 5) -> List[Dict]:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë¯¸ë¦¬ë³´ê¸°"""
        try:
            stores = self.migration.get_crawler_stores(limit)
            preview_data = []
            
            for store in stores:
                try:
                    processed_data = self.migration.process_store_data(store)
                    preview_data.append({
                        'name': processed_data['name'],
                        'address': processed_data['address'],
                        'categories': processed_data['categories'],
                        'refill_items': processed_data['refill_items'],
                        'position': f"({processed_data['position_lat']}, {processed_data['position_lng']})"
                    })
                except Exception as e:
                    logger.error(f"ë¯¸ë¦¬ë³´ê¸° ì²˜ë¦¬ ì‹¤íŒ¨ ({store.get('name', 'Unknown')}): {e}")
                    continue
            
            return preview_data
            
        except Exception as e:
            logger.error(f"ë¯¸ë¦¬ë³´ê¸° ìƒì„± ì‹¤íŒ¨: {e}")
            return []


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Supabase MCP ë§ˆì´ê·¸ë ˆì´ì…˜')
    parser.add_argument('--limit', type=int, help='ë§ˆì´ê·¸ë ˆì´ì…˜í•  ê°€ê²Œ ìˆ˜ ì œí•œ')
    parser.add_argument('--batch-size', type=int, default=5, help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 5)')
    parser.add_argument('--preview', action='store_true', help='ë§ˆì´ê·¸ë ˆì´ì…˜ ë¯¸ë¦¬ë³´ê¸°')
    parser.add_argument('--test', action='store_true', help='ì—°ê²° í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰')
    
    args = parser.parse_args()
    
    migration = SupabaseMCPMigration()
    
    try:
        if args.test:
            logger.info("ğŸ” Supabase ì—°ê²° í…ŒìŠ¤íŠ¸...")
            success = await migration.test_connection()
            if success:
                print("âœ… ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
            else:
                print("âŒ ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!")
                
        elif args.preview:
            logger.info("ğŸ‘€ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¯¸ë¦¬ë³´ê¸°...")
            preview_data = await migration.get_migration_preview(args.limit or 5)
            
            print("\n" + "="*60)
            print("ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ë¯¸ë¦¬ë³´ê¸°")
            print("="*60)
            
            for i, data in enumerate(preview_data, 1):
                print(f"\n{i}. {data['name']}")
                print(f"   ì£¼ì†Œ: {data['address']}")
                print(f"   ì¹´í…Œê³ ë¦¬: {', '.join(data['categories'])}")
                print(f"   ë¦¬í•„ì•„ì´í…œ: {', '.join(data['refill_items'][:3])}...")
                print(f"   ìœ„ì¹˜: {data['position']}")
            
            print("="*60)
            
        else:
            logger.info("ğŸš€ ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰...")
            stats = await migration.execute_migration(
                limit=args.limit,
                batch_size=args.batch_size
            )
            
            print("\n" + "="*50)
            print("ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼")
            print("="*50)
            print(f"ì´ ì²˜ë¦¬: {stats['total']}ê°œ")
            print(f"ì„±ê³µ: {stats['success']}ê°œ")
            print(f"ì‹¤íŒ¨: {stats['failed']}ê°œ")
            print(f"ì„±ê³µë¥ : {stats['success']/stats['total']*100:.1f}%")
            print("="*50)
            
    except Exception as e:
        logger.error(f"âŒ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        raise


if __name__ == "__main__":
    asyncio.run(main()) 