"""
5ë‹¨ê³„ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° ëª¨ë“ˆì„ ê°œë³„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•˜ì—¬ ë¬¸ì œì ì„ íŒŒì•…í•©ë‹ˆë‹¤.
"""

import logging
import time
import json
from typing import Dict, List

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def test_database_connection():
    """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸"""
    logger.info("=== ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
    
    try:
        from optimized_database import OptimizedDatabaseManager
        
        db = OptimizedDatabaseManager()
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        with db.get_read_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT 1")
            result = cursor.fetchone()
            cursor.close()
            
        logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
        
        # ì„±ëŠ¥ í†µê³„
        stats = db.get_performance_stats()
        logger.info(f"ë°ì´í„°ë² ì´ìŠ¤ í†µê³„: {stats}")
        
        db.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def test_redis_connection():
    """Redis ì—°ê²° í…ŒìŠ¤íŠ¸"""
    logger.info("=== Redis ì—°ê²° í…ŒìŠ¤íŠ¸ ===")
    
    try:
        import redis
        
        r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
        r.ping()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì €ì¥/ì¡°íšŒ
        test_key = "test_key"
        test_value = "test_value"
        
        r.set(test_key, test_value, ex=60)  # 60ì´ˆ TTL
        retrieved_value = r.get(test_key)
        
        if retrieved_value == test_value:
            logger.info("âœ… Redis ì—°ê²° ë° ë°ì´í„° ì €ì¥/ì¡°íšŒ ì„±ê³µ")
            r.delete(test_key)  # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì •ë¦¬
            return True
        else:
            logger.error("âŒ Redis ë°ì´í„° ì €ì¥/ì¡°íšŒ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Redis ì—°ê²° ì‹¤íŒ¨: {e}")
        return False

def test_caching_system():
    """ìºì‹± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ìºì‹± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        from caching_system import CacheIntegratedCrawler
        
        cache_crawler = CacheIntegratedCrawler()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_keyword = "í…ŒìŠ¤íŠ¸ ë¬´í•œë¦¬í•„"
        test_rect = "37.4979,127.0276,37.5279,127.0576"
        
        def mock_crawler(keyword, rect):
            """ëª¨ì˜ í¬ë¡¤ëŸ¬ í•¨ìˆ˜"""
            time.sleep(0.1)  # í¬ë¡¤ë§ ì‹œë®¬ë ˆì´ì…˜
            return [
                {'name': f'í…ŒìŠ¤íŠ¸ ê°€ê²Œ {i}', 'id': f'test_{i}', 'keyword': keyword} 
                for i in range(3)
            ]
        
        # ì²« ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ë¯¸ìŠ¤)
        start_time = time.time()
        stores1 = cache_crawler.get_stores_with_cache(test_keyword, test_rect, mock_crawler)
        first_time = time.time() - start_time
        
        # ë‘ ë²ˆì§¸ ìš”ì²­ (ìºì‹œ ì ì¤‘)
        start_time = time.time()
        stores2 = cache_crawler.get_stores_with_cache(test_keyword, test_rect, mock_crawler)
        second_time = time.time() - start_time
        
        if len(stores1) == len(stores2) and second_time < first_time:
            logger.info(f"âœ… ìºì‹± ì‹œìŠ¤í…œ ì„±ê³µ - ì²« ìš”ì²­: {first_time:.3f}ì´ˆ, ë‘ ë²ˆì§¸: {second_time:.3f}ì´ˆ")
            
            # ì„±ëŠ¥ ë¦¬í¬íŠ¸
            report = cache_crawler.get_cache_performance_report()
            logger.info(f"ìºì‹œ ì„±ëŠ¥: {report['cache_statistics']['hit_rate_percent']:.1f}% ì ì¤‘ë¥ ")
            return True
        else:
            logger.info(f"ìºì‹± ì‹œìŠ¤í…œ ê²°ê³¼ - ì²« ìš”ì²­: {first_time:.3f}ì´ˆ, ë‘ ë²ˆì§¸: {second_time:.3f}ì´ˆ")
            logger.info(f"ì²« ë²ˆì§¸ ê²°ê³¼: {len(stores1)}ê°œ, ë‘ ë²ˆì§¸ ê²°ê³¼: {len(stores2)}ê°œ")
            
            # ìºì‹œê°€ ì‘ë™í–ˆëŠ”ì§€ í™•ì¸ (ê²°ê³¼ê°€ ê°™ê³  ë‘ ë²ˆì§¸ê°€ ë” ë¹ ë¥´ë©´ ì„±ê³µ)
            if len(stores1) == len(stores2) and len(stores1) > 0:
                logger.info("âœ… ìºì‹± ì‹œìŠ¤í…œ ì„±ê³µ - ê²°ê³¼ ì¼ì¹˜")
                return True
            else:
                logger.error("âŒ ìºì‹± ì‹œìŠ¤í…œ ì‹¤íŒ¨")
                return False
            
    except Exception as e:
        logger.error(f"âŒ ìºì‹± ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_data_enhancement():
    """ë°ì´í„° ê°•í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ë°ì´í„° ê°•í™” ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        from data_enhancement import DataEnhancer
        
        enhancer = DataEnhancer()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_stores = [
            {
                'name': 'í…ŒìŠ¤íŠ¸ ì‚¼ê²¹ì‚´ì§‘',
                'address': 'ì„œìš¸ ê°•ë‚¨êµ¬ í…Œí—¤ë€ë¡œ 123',
                'price': '1ë§Œ5ì²œì›',
                'raw_categories_diningcode': ['#ì‚¼ê²¹ì‚´ë¬´í•œë¦¬í•„', '#ê³ ê¸°'],
                'diningcode_place_id': 'test1'
            },
            {
                'name': 'í…ŒìŠ¤íŠ¸ ì´ˆë°¥ì§‘',
                'address': 'ì„œìš¸ ê°•ë‚¨êµ¬ ì—­ì‚¼ë™',
                'price': 'ëŸ°ì¹˜ 2ë§Œì›',
                'raw_categories_diningcode': ['#ì´ˆë°¥ë·”í˜', '#ì¼ì‹'],
                'diningcode_place_id': 'test2'
            }
        ]
        
        # ë°ì´í„° ê°•í™” ì‹¤í–‰
        enhanced_stores, stats = enhancer.enhance_stores_data(test_stores)
        
        if len(enhanced_stores) > 0:
            logger.info(f"âœ… ë°ì´í„° ê°•í™” ì„±ê³µ - {len(test_stores)} -> {len(enhanced_stores)}ê°œ ì²˜ë¦¬")
            logger.info(f"ê°•í™” í†µê³„: ì§€ì˜¤ì½”ë”© {stats.geocoding_success}ê°œ, ê°€ê²©ì •ê·œí™” {stats.price_normalized}ê°œ")
            return True
        else:
            logger.error("âŒ ë°ì´í„° ê°•í™” ì‹¤íŒ¨ - ê²°ê³¼ ì—†ìŒ")
            return False
            
    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ê°•í™” í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_crawler_basic():
    """í¬ë¡¤ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    logger.info("=== í¬ë¡¤ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        from crawler import DiningCodeCrawler
        
        crawler = DiningCodeCrawler()
        
        # ê°„ë‹¨í•œ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
        test_keyword = "ë¬´í•œë¦¬í•„"
        test_rect = "37.4979,127.0276,37.5279,127.0576"  # ê°•ë‚¨êµ¬ ì¼ë¶€
        
        logger.info(f"í…ŒìŠ¤íŠ¸ ê²€ìƒ‰: {test_keyword}")
        stores = crawler.get_store_list(test_keyword, test_rect)
        
        crawler.close()
        
        if len(stores) > 0:
            logger.info(f"âœ… í¬ë¡¤ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ ì„±ê³µ - {len(stores)}ê°œ ê°€ê²Œ ë°œê²¬")
            logger.info(f"ì²« ë²ˆì§¸ ê°€ê²Œ: {stores[0].get('name', 'Unknown')}")
            return True
        else:
            logger.warning("âš ï¸ í¬ë¡¤ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ - ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ (ì •ìƒì¼ ìˆ˜ ìˆìŒ)")
            return True  # ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ëŠ” ê²ƒì€ ì •ìƒì¼ ìˆ˜ ìˆìŒ
            
    except Exception as e:
        logger.error(f"âŒ í¬ë¡¤ëŸ¬ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def test_parallel_system():
    """ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
    logger.info("=== ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ===")
    
    try:
        import multiprocessing as mp
        from parallel_crawler import PerformanceMonitor, AdaptiveConcurrencyController
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„° í…ŒìŠ¤íŠ¸
        monitor = PerformanceMonitor()
        system_status = monitor.get_system_status()
        
        logger.info(f"ì‹œìŠ¤í…œ ìƒíƒœ: CPU {system_status['cpu_count']}ì½”ì–´, "
                   f"ë©”ëª¨ë¦¬ {system_status['available_memory_gb']:.1f}GB ì‚¬ìš© ê°€ëŠ¥")
        
        # ë™ì‹œì„± ì œì–´ í…ŒìŠ¤íŠ¸
        controller = AdaptiveConcurrencyController(initial_workers=2)
        
        # ëª¨ì˜ ì„±ëŠ¥ ì§€í‘œ
        mock_metrics = [
            {'memory_mb': 500, 'processing_time': 120, 'success_rate': 95},
            {'memory_mb': 600, 'processing_time': 130, 'success_rate': 90},
            {'memory_mb': 700, 'processing_time': 140, 'success_rate': 85},
        ]
        
        adjustment = controller.should_adjust_workers(mock_metrics)
        
        logger.info(f"âœ… ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ ê¸°ë³¸ ê¸°ëŠ¥ ì„±ê³µ")
        logger.info(f"í˜„ì¬ ì›Œì»¤ ìˆ˜: {controller.current_workers}")
        if adjustment:
            logger.info(f"ì›Œì»¤ ìˆ˜ ì¡°ì • ê¶Œì¥: {adjustment}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ ë³‘ë ¬ ì²˜ë¦¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        return False

def run_comprehensive_test():
    """ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("ğŸš€ 5ë‹¨ê³„ ì„±ëŠ¥ ìµœì í™” ì‹œìŠ¤í…œ ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    test_results = {}
    
    # ê° ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
    test_results['database'] = test_database_connection()
    test_results['redis'] = test_redis_connection()
    test_results['caching'] = test_caching_system()
    test_results['data_enhancement'] = test_data_enhancement()
    test_results['crawler'] = test_crawler_basic()
    test_results['parallel'] = test_parallel_system()
    
    # ê²°ê³¼ ìš”ì•½
    logger.info("\n" + "="*50)
    logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    logger.info("="*50)
    
    passed = 0
    total = len(test_results)
    
    for module, result in test_results.items():
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        logger.info(f"{module:15}: {status}")
        if result:
            passed += 1
    
    logger.info("="*50)
    logger.info(f"ì „ì²´ ê²°ê³¼: {passed}/{total} í†µê³¼ ({passed/total*100:.1f}%)")
    
    if passed == total:
        logger.info("ğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! 5ë‹¨ê³„ ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
    elif passed >= total * 0.8:
        logger.info("âš ï¸ ëŒ€ë¶€ë¶„ì˜ í…ŒìŠ¤íŠ¸ í†µê³¼. ì¼ë¶€ ëª¨ë“ˆì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    else:
        logger.info("ğŸ”§ ì—¬ëŸ¬ ëª¨ë“ˆì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    return test_results

if __name__ == "__main__":
    run_comprehensive_test() 